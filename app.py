import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (ë¡œì»¬ê³¼ Streamlit Cloud ëª¨ë‘ ì§€ì›)
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# Streamlit Secretsì—ì„œë„ API í‚¤ í™•ì¸ (Streamlit Cloud ë°°í¬ìš©)
if not API_KEY and 'GOOGLE_API_KEY' in st.secrets:
    API_KEY = st.secrets['GOOGLE_API_KEY']

# API í‚¤ í™•ì¸
if not API_KEY:
    st.error("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# Google Gemini API ì„¤ì •
genai.configure(api_key=API_KEY)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Gemini Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ¤– Gemini ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."

# ì‚¬ì´ë“œë°”ì— í”„ë¡¬í”„íŠ¸ í¸ì§‘ ì˜ì—­ ì¶”ê°€
with st.sidebar:
    st.subheader("í”„ë¡¬í”„íŠ¸ ì„¤ì •")
    new_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •", st.session_state.system_prompt, height=150)
    if st.button("í”„ë¡¬í”„íŠ¸ ì ìš©"):
        st.session_state.system_prompt = new_prompt
        st.success("âœ… ìƒˆ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
if st.sidebar.button("ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°"):
    st.session_state.messages = []
    st.rerun()

# ì´ì „ ì±„íŒ… ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    try:
        # ëª¨ë¸ ì„¤ì •
        model = genai.GenerativeModel("models/gemini-1.5-flash")
        
        # ê³ ì • í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì ì…ë ¥ì„ í•©ì³ì„œ ì „ì†¡
        full_prompt = f"{st.session_state.system_prompt}\n\nì‚¬ìš©ì: {user_input}"
        
        # ì±„íŒ… ê¸°ë¡ì´ ìˆëŠ” ê²½ìš° ì´ì „ ëŒ€í™” ë§¥ë½ ì¶”ê°€
        if len(st.session_state.messages) > 1:
            chat_history = ""
            for msg in st.session_state.messages[:-1]:  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(ë°©ê¸ˆ ì…ë ¥í•œ ê²ƒ) ì œì™¸
                prefix = "ì‚¬ìš©ì: " if msg["role"] == "user" else "AI: "
                chat_history += f"{prefix}{msg['content']}\n"
            full_prompt = f"{st.session_state.system_prompt}\n\n{chat_history}\nì‚¬ìš©ì: {user_input}"
        
        response = model.generate_content(full_prompt)
        
        # ë´‡ ì‘ë‹µ í‘œì‹œ
        bot_reply = response.text
        st.chat_message("assistant").markdown(bot_reply)
        st.session_state.messages.append({"role": "assistant", "content": bot_reply})
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}") 